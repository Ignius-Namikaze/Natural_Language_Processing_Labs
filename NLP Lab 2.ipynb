{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a26e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db35b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\"cat\", \"dog\", \"fish\", \"dog\", \"cat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d40e2",
   "metadata": {},
   "source": [
    "# To implement label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8669bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(text_data)\n",
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125fbd9e",
   "metadata": {},
   "source": [
    "# To implement one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757f5cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "text_data_reshaped = [[label] for label in text_data]\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_encoded_data = one_hot_encoder.fit_transform(text_data_reshaped)\n",
    "dense_encoded_data = one_hot_encoded_data.toarray()\n",
    "print(dense_encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689e6d0",
   "metadata": {},
   "source": [
    "# To implement BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23df68b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (unique words): {'runs', 'lazy', 'dog', 'fox', 'brown', 'over', 'quickly', 'quick', 'barks', 'jumps', 'the'}\n",
      "Bag of Words Matrix:\n",
      "[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
      "[0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "sample_data = [\n",
    "    \"The quick brown fox\",\n",
    "    \"jumps over the lazy dog\",\n",
    "    \"The dog barks\",\n",
    "    \"The fox runs quickly\",\n",
    "]\n",
    "\n",
    "tokenized_text = [sentence.lower().split() for sentence in sample_data]\n",
    "\n",
    "vocabulary = set(word for sentence in tokenized_text for word in sentence)\n",
    "\n",
    "bow_matrix = []\n",
    "\n",
    "for sentence in tokenized_text:\n",
    "    bow_vector = [sentence.count(word) for word in vocabulary]\n",
    "    bow_matrix.append(bow_vector)\n",
    "\n",
    "print(\"Vocabulary (unique words):\", vocabulary)\n",
    "\n",
    "print(\"Bag of Words Matrix:\")\n",
    "for row in bow_matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61412e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def create_bag_of_words(texts):\n",
    "    bag_of_words = Counter()\n",
    "    \n",
    "    for text in texts:\n",
    "        preprocessed_text = preprocess_text(text)\n",
    "        words = preprocessed_text.split()\n",
    "        bag_of_words.update(words)\n",
    "    \n",
    "    return bag_of_words\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"This is an example sentence.\",\n",
    "    \"Another example for demonstration.\",\n",
    "    \"Example sentences help illustrate concepts.\"\n",
    "]\n",
    "\n",
    "bag_of_words = create_bag_of_words(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e611ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'example': 3, 'this': 1, 'is': 1, 'an': 1, 'sentence': 1, 'another': 1, 'for': 1, 'demonstration': 1, 'sentences': 1, 'help': 1, 'illustrate': 1, 'concepts': 1})\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503fa415",
   "metadata": {},
   "source": [
    "# Explore Scikit learn to implement TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e4c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['an' 'another' 'concepts' 'demonstration' 'example' 'for' 'help'\n",
      " 'illustrate' 'is' 'sentence' 'sentences' 'this']\n",
      "TF-IDF Matrix:\n",
      "[[0.47952794 0.         0.         0.         0.28321692 0.\n",
      "  0.         0.         0.47952794 0.47952794 0.         0.47952794]\n",
      " [0.         0.54645401 0.         0.54645401 0.32274454 0.54645401\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.47952794 0.         0.28321692 0.\n",
      "  0.47952794 0.47952794 0.         0.         0.47952794 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"This is an example sentence.\",\n",
    "    \"Another example for demonstration.\",\n",
    "    \"Example sentences help illustrate concepts.\"\n",
    "]\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the texts using the vectorizer\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Get the feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense array for easier manipulation\n",
    "dense_matrix = tfidf_matrix.toarray()\n",
    "\n",
    "# Print the feature names and TF-IDF matrix\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(dense_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b209f",
   "metadata": {},
   "source": [
    "# To implement TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881a36b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08109302162163289, 0.0, 0.0, 0.0, -0.05753641449035618, 0.0, 0.0, 0.0, 0.08109302162163289, 0.08109302162163289, 0.0, 0.08109302162163289]\n",
      "[0.0, 0.1013662770270411, 0.0, 0.1013662770270411, -0.07192051811294523, 0.1013662770270411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.08109302162163289, 0.0, -0.05753641449035618, 0.0, 0.08109302162163289, 0.08109302162163289, 0.0, 0.0, 0.08109302162163289, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"This is an example sentence.\",\n",
    "    \"Another example for demonstration.\",\n",
    "    \"Example sentences help illustrate concepts.\"\n",
    "]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def compute_tf(text):\n",
    "    words = preprocess_text(text).split()\n",
    "    word_count = Counter(words)\n",
    "    total_words = len(words)\n",
    "    \n",
    "    tf_values = {word: count / total_words for word, count in word_count.items()}\n",
    "    return tf_values\n",
    "\n",
    "def compute_idf(texts):\n",
    "    num_documents = len(texts)\n",
    "    word_to_document_count = Counter()\n",
    "    \n",
    "    for text in texts:\n",
    "        words = set(preprocess_text(text).split())\n",
    "        word_to_document_count.update(words)\n",
    "    \n",
    "    idf_values = {word: math.log(num_documents / (count + 1)) for word, count in word_to_document_count.items()}\n",
    "    return idf_values\n",
    "\n",
    "# Compute TF and IDF values\n",
    "tf_values = [compute_tf(text) for text in texts]\n",
    "idf_values = compute_idf(texts)\n",
    "\n",
    "# Create a sorted list of unique words from both TF and IDF dictionaries\n",
    "unique_words = sorted(set(word for tf_dict in tf_values for word in tf_dict) | set(idf_values))\n",
    "\n",
    "# Compute TF-IDF matrix\n",
    "tfidf_matrix = []\n",
    "\n",
    "for tf in tf_values:\n",
    "    tfidf_vector = [tf.get(word, 0) * idf_values.get(word, 0) for word in unique_words]\n",
    "    tfidf_matrix.append(tfidf_vector)\n",
    "\n",
    "# Print TF-IDF matrix\n",
    "for row in tfidf_matrix:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a24d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
